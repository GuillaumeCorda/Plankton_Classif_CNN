{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T09:44:26.371749Z",
     "start_time": "2018-11-29T09:44:22.886730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pylab\n",
    "import cv2\n",
    "\n",
    "from scipy.stats import moment \n",
    "from scipy.ndimage import shift\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Dense, Dropout, Flatten, MaxPooling2D, Conv2D, Activation, Input, Embedding, concatenate\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from skimage import segmentation, morphology, measure\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import watershed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths and model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:56.800401Z",
     "start_time": "2018-11-29T11:29:56.786740Z"
    }
   },
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    def __init__(self, path, data_location='data/', train_images_location='data/train_images/',\n",
    "                 test_images_location='/data/test_images/', image_size=56, n_classes=121, batch_size=64,\n",
    "                 n_epochs=10):\n",
    "        self.path = path\n",
    "        self.data_location = self.path + data_location\n",
    "        self.train_images_location = self.path + train_images_location\n",
    "        self.test_images_location = self.path + test_images_location \n",
    "        self.image_size = image_size\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:57.427013Z",
     "start_time": "2018-11-29T11:29:57.422995Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CONFIG(path='/Users/guillaumecorda/Desktop/UvA/Applied Machine Learning/Kaggle/aml_kaggle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:57.579449Z",
     "start_time": "2018-11-29T11:29:57.575891Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/Users/guillaumecorda/Desktop/UvA/Applied Machine Learning/Kaggle/data/train_images/'\n",
    "validation_dir = '/Users/guillaumecorda/Desktop/UvA/Applied Machine Learning/Kaggle/data/val_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process image data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:47:47.995835Z",
     "start_time": "2018-11-25T16:47:47.985534Z"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:58.321893Z",
     "start_time": "2018-11-29T11:29:57.994009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load train images filenames with class labels\n",
    "filenames = [i for i in os.listdir(cfg.path+'data/train_images') if i.endswith('.jpg')]\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    file_to_class = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "# Calculate new class counts, converging towards max (1580)\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    class_counts = {}\n",
    "    for row in reader:\n",
    "        if(row[1] != 'class'):\n",
    "            class_counts[int(row[1])] = class_counts.get(int(row[1]), 0) + 1\n",
    "    max_nr = max(class_counts.values())\n",
    "    for key, value in class_counts.items():\n",
    "        class_counts[key] = int(class_counts[key] + (max_nr - class_counts[key])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:29:58.352759Z",
     "start_time": "2018-11-29T11:29:58.333748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X:(24204, 56, 56, 1)\n",
      "Y:(51985, 121)\n"
     ]
    }
   ],
   "source": [
    "X = np.empty([len(filenames),cfg.image_size, cfg.image_size, 1])\n",
    "Y_tmp = np.empty([len(filenames)])\n",
    "Y = np.empty([sum(class_counts.values()),cfg.n_classes])\n",
    "print('Shapes:\\nX:{}\\nY:{}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T09:44:28.095915Z",
     "start_time": "2018-11-29T09:44:28.082673Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_padding(i):\n",
    "    \"\"\"\n",
    "    Helper function for getting right padding sizes\n",
    "    input:\n",
    "        - i: positive integer gotten from substracting height and width of an image\n",
    "    output:\n",
    "        - Tuple representing the correct padding\n",
    "    \"\"\"\n",
    "    if i%2 == 0:\n",
    "        return (int(i/2),int(i/2))\n",
    "    else:\n",
    "        return (int(i/2-.5), int(i/2+.5))\n",
    "\n",
    "def pad_image(img):\n",
    "    \"\"\"\n",
    "    Add padding to image to make it square\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "    output:\n",
    "        - padded array of shape (N,N)\n",
    "    \"\"\"\n",
    "    H, W = img.shape\n",
    "    if H == W:\n",
    "        return img\n",
    "    elif H > W:\n",
    "        return np.pad(img, ((0,0), get_padding(H-W)), 'constant')\n",
    "    else:\n",
    "        return np.pad(img, (get_padding(W-H), (0,0)), 'constant')\n",
    "\n",
    "def resize_image(img):\n",
    "    \"\"\"\n",
    "    Resize image to new square shape\n",
    "    input:\n",
    "        - img: numpy array (2D) representing image\n",
    "        - size: final shape of image in pixels (integer)\n",
    "    \"\"\"\n",
    "    return resize(img, (cfg.image_size, cfg.image_size), mode='reflect')\n",
    "\n",
    "\n",
    "def find_highest_dimensions(path):\n",
    "    \n",
    "    path = cfg.path+path\n",
    "    images_names = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    max_rows = 0\n",
    "    max_cols = 0\n",
    "    \n",
    "    for image in images_names:\n",
    "        try:\n",
    "            im = np.asarray(PIL.Image.open(path+image))\n",
    "            if im.shape[0] > max_rows:\n",
    "                max_rows = im.shape[0]\n",
    "            if im.shape[1] > max_cols:\n",
    "                max_cols = im.shape[1]\n",
    "        except:\n",
    "            print('Image {} failed.\\n'.format(image))\n",
    "    max_shape = (max_rows, max_cols)\n",
    "    \n",
    "    return max_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For image in filenames:\n",
    "- load file\n",
    "- from [0,255] to [0.0 to 1.0]\n",
    "- square and resize image\n",
    "- either:\n",
    "    - add image once (X & Y)\n",
    "- or:\n",
    "    - rotate [0,90,180,270]\n",
    "    - add 4 images to X\n",
    "    - add 4 labels to Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:32:05.018910Z",
     "start_time": "2018-11-29T11:30:01.035892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X:(24204, 56, 56, 1)\n",
      "Y:(51985, 121)\n"
     ]
    }
   ],
   "source": [
    "total = len(filenames)\n",
    "for i in range(len(filenames)):\n",
    "    # read and transform image to usable format\n",
    "    img = mpimg.imread(cfg.train_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    # create a grayscale channel \n",
    "    img = img.reshape(cfg.image_size, cfg.image_size, 1)\n",
    "    \n",
    "    X[i] = img\n",
    "    Y_tmp[i] = int(file_to_class[filenames[i]])\n",
    "    \n",
    "print('Shapes:\\nX:{}\\nY:{}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:32:05.127348Z",
     "start_time": "2018-11-29T11:32:05.078032Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_new_features(filenames):\n",
    "    N = len(filenames)\n",
    "    output = np.zeros((N,9))\n",
    "    for i, image in enumerate(filenames):\n",
    "        image = mpimg.imread(cfg.train_images_location + filenames[i])\n",
    "        h = image.shape[0]\n",
    "        w = image.shape[1]\n",
    "        h_ = h/w\n",
    "        w_ = w/h\n",
    "        h_2 = (h/w)**2\n",
    "        w_2 = (w/h)**2\n",
    "        m = np.mean(image)\n",
    "        moment_2 = moment(image.flatten(), moment=2)\n",
    "        moment_3 = moment(image.flatten(), moment=3)\n",
    "        output[i] = np.array([h, w, h_, w_, h_2, w_2, m, moment_2, moment_3])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T19:22:35.435112Z",
     "start_time": "2018-11-28T19:22:22.147710Z"
    }
   },
   "outputs": [],
   "source": [
    "new_features = compute_new_features(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Height/Widths Amongst Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T12:24:05.936543Z",
     "start_time": "2018-11-28T12:24:05.901662Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(new_features[:,0], new_features[:,1], c=Y_tmp.tolist(), cmap=pylab.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:37:07.961758Z",
     "start_time": "2018-11-27T16:37:07.751446Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(new_features[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:37:59.450540Z",
     "start_time": "2018-11-27T16:37:59.443531Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_height = np.median(new_features[:,0])\n",
    "mean_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:37:21.519366Z",
     "start_time": "2018-11-27T16:37:21.306299Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(new_features[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:38:13.645325Z",
     "start_time": "2018-11-27T16:38:13.637896Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_width = np.median(new_features[:,1])\n",
    "mean_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:30:47.140053Z",
     "start_time": "2018-11-28T14:30:46.972906Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(16,3))\n",
    "sub1 = plt.subplot(1,4,1)\n",
    "plt.imshow(X[250][:,:,0], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T14:30:47.334335Z",
     "start_time": "2018-11-28T14:30:47.177806Z"
    }
   },
   "outputs": [],
   "source": [
    "val = shift(X[250][:,:,0], -10)\n",
    "plt.imshow(val, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotations and shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:32:15.641189Z",
     "start_time": "2018-11-29T11:32:05.135248Z"
    }
   },
   "outputs": [],
   "source": [
    "X_augm = np.concatenate((X, X, X, X, X, X, X, X))\n",
    "\n",
    "Y_augm = np.concatenate((Y_tmp, Y_tmp, Y_tmp, Y_tmp, Y_tmp, Y_tmp, Y_tmp, Y_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:33:16.997261Z",
     "start_time": "2018-11-29T11:32:15.731430Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rotate images by one of 0/90/180/270 degrees\n",
    "for i in range(X.shape[0], 2*X.shape[0]):\n",
    "    X_augm[i] = np.rot90(X_augm[i],(1+(i%4)))\n",
    "    \n",
    "#flip images\n",
    "for i in range(2*X.shape[0], 3*X.shape[0]):\n",
    "    X_augm[i] = np.fliplr(X_augm[i])\n",
    "\n",
    "#flip and rotation images\n",
    "for i in range(3*X.shape[0], 4*X.shape[0]):\n",
    "    X_augm[i] = np.fliplr(X_augm[i])\n",
    "    X_augm[i] = np.rot90(X_augm[i],(1+(i%4)))\n",
    "\n",
    "#flip images\n",
    "for i in range(4*X.shape[0], 5*X.shape[0]):\n",
    "    X_augm[i] = np.flipud(X_augm[i])\n",
    "\n",
    "#flip and rotation images\n",
    "for i in range(5*X.shape[0], 6*X.shape[0]):\n",
    "    X_augm[i] = np.flipud(X_augm[i])\n",
    "    X_augm[i] = np.rot90(X_augm[i],(1+(i%4)))\n",
    "\n",
    "#shift\n",
    "for i in range(6*X.shape[0], 7*X.shape[0]):\n",
    "    #shift = np.random.uniform(low=-cfg.image_size//2, high=cfg.image_size//2)\n",
    "    val = shift(X_augm[i][:,:,0], 10)\n",
    "    X_augm[i] = val.reshape(cfg.image_size, cfg.image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T09:44:15.981812Z",
     "start_time": "2018-11-29T09:44:12.044Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check transformations\n",
    "for i in range(7):\n",
    "    f = plt.figure(figsize=(16,3))\n",
    "    sub1 = plt.subplot(1,4,1)\n",
    "    plt.imshow(X_augm[i*total][:,:,0], cmap='binary')\n",
    "    plt.imshow(X_augm[i*total][:,:,0], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance\n",
    "Since there is a strong class imbalance (lowest 7, highest 1580), something has to be done to counter this. Oversampling minority classes to be as big as the majority classes is the option used below. <br>\n",
    "(Please do note that the validation split accuracy can not be seen as a surrogate for the test set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:54:33.779423Z",
     "start_time": "2018-11-27T15:54:32.660189Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.reshape(total,cfg.image_size*cfg.image_size)\n",
    "print(X.shape)\n",
    "\n",
    "sm = RandomOverSampler(ratio=class_counts)\n",
    "X, Y_tmp = sm.fit_sample(X, Y_tmp)\n",
    "print('Shapes:\\nX:{}\\nY:{}'.format(X.shape, Y_tmp.shape))\n",
    "\n",
    "X = X.reshape(len(X),cfg.image_size,cfg.image_size,1)\n",
    "for i in range(len(Y_tmp)):\n",
    "    Y[i][int(Y_tmp[i])] = 1.0\n",
    "del(Y_tmp)\n",
    "print('Shapes:\\nX:{}\\nY:{}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:54:34.270824Z",
     "start_time": "2018-11-27T15:54:33.783092Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(total, X.shape[0]):\n",
    "    # rotate RandomOverSampler images by one of 0/90/180/270 degrees\n",
    "    X[i] = np.rot90(X[i],(1+(i%4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the lines below appropriately if a validation split is to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:54:34.276562Z",
     "start_time": "2018-11-27T15:54:34.273407Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "# only uncomment if train/validation variables are used\n",
    "# del(X)\n",
    "# del(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:13:37.489045Z",
     "start_time": "2018-11-28T20:13:37.482806Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:13:38.060554Z",
     "start_time": "2018-11-28T20:13:38.054412Z"
    }
   },
   "outputs": [],
   "source": [
    "X_augm = X_augm.reshape((X_augm.shape[0], X_augm.shape[1]*X_augm.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:13:38.477986Z",
     "start_time": "2018-11-28T20:13:38.471543Z"
    }
   },
   "outputs": [],
   "source": [
    "X_augm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:40.777Z"
    }
   },
   "outputs": [],
   "source": [
    "#ratio : the desired ratio of the number of samples in the majority class \n",
    "#        over the number of samples in the minority class after resampling.\n",
    "X_resampled, Y_resampled = SMOTE(random_state=42).fit_resample(X_augm, Y_augm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:41.336Z"
    }
   },
   "outputs": [],
   "source": [
    "X_resampled = X_resampled.reshape((X_resampled.shape[0], cfg.image_size, cfg.image_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:41.507Z"
    }
   },
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:41.692Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:41.839Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_resampled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:42.031Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_resampled[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:33:17.128589Z",
     "start_time": "2018-11-29T11:33:17.011873Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_targets(y_true):\n",
    "    N = len(y_true)\n",
    "    output = np.zeros(shape=(N, 121))\n",
    "    for i in range(N):\n",
    "        j=0\n",
    "        while j != y_true[i]:\n",
    "            j+=1\n",
    "        output[i][j]=1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:33:45.776270Z",
     "start_time": "2018-11-29T11:33:17.130961Z"
    }
   },
   "outputs": [],
   "source": [
    "#to do if RandomOverSampling not used\n",
    "#Y_resampled = format_targets(Y_resampled)\n",
    "Y_augm = format_targets(Y_augm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-28T20:13:47.302Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_tmp = format_targets(Y_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN no reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:33:48.116806Z",
     "start_time": "2018-11-29T11:33:45.786286Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               803328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 121)               62073     \n",
      "=================================================================\n",
      "Total params: 1,134,161\n",
      "Trainable params: 1,134,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=X_augm[0].shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(8, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:34:13.768842Z",
     "start_time": "2018-11-29T11:33:48.119574Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2880/193632 [..............................] - ETA: 25:35 - loss: 2690.6686 - acc: 0.0979"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c76e6c782ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     class_weight=class_counts)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_augm, \n",
    "    Y_augm,\n",
    "    epochs=5, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1,\n",
    "    class_weight=class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T10:26:58.212070Z",
     "start_time": "2018-11-29T10:26:57.622402Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 121)               62073     \n",
      "=================================================================\n",
      "Total params: 625,145\n",
      "Trainable params: 625,049\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=X_augm[0].shape))\n",
    "                 #kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:22:18.001014Z",
     "start_time": "2018-11-29T10:26:58.216406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "193632/193632 [==============================] - 720s 4ms/step - loss: 2198.4603 - acc: 0.1814\n",
      "Epoch 2/5\n",
      "193632/193632 [==============================] - 663s 3ms/step - loss: 1673.4949 - acc: 0.2761\n",
      "Epoch 3/5\n",
      "193632/193632 [==============================] - 692s 4ms/step - loss: 1483.3934 - acc: 0.3187\n",
      "Epoch 4/5\n",
      "193632/193632 [==============================] - 697s 4ms/step - loss: 1375.0587 - acc: 0.3483\n",
      "Epoch 5/5\n",
      "129280/193632 [===================>..........] - ETA: 4:31 - loss: 1309.6124 - acc: 0.3679"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c76e6c782ba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     class_weight=class_counts)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_augm, \n",
    "    Y_augm,\n",
    "    epochs=5, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1,\n",
    "    class_weight=class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to change optimizer to adam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:33:05.232397Z",
     "start_time": "2018-11-28T17:33:02.666960Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = load_model(cfg.path+'/output_guillaume/models/model_3_BEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:25:24.151122Z",
     "start_time": "2018-11-28T16:53:42.096444Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_augm, \n",
    "    Y_augm,\n",
    "    epochs=3, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1,\n",
    "    class_weight=class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T17:26:05.548771Z",
     "start_time": "2018-11-28T17:26:05.175481Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(cfg.path+'/output_guillaume/models/model_5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:02:24.596088Z",
     "start_time": "2018-11-25T20:02:24.371518Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(cfg.path+'/data/test_images') if i.endswith('.jpg')]\n",
    "\n",
    "labels = pd.DataFrame(filenames, columns=['image'])\n",
    "labels['class'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:03:18.786075Z",
     "start_time": "2018-11-25T20:02:30.653442Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(filenames)\n",
    "for i in range(total):\n",
    "    # read and transform image to usable format\n",
    "    img = mpimg.imread(cfg.test_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    # uncomment next line if ConvLayer in Model \n",
    "    img = img.reshape(1,cfg.image_size, cfg.image_size,1)\n",
    "    # uncomment next line if no ConvLayer in Model\n",
    "    # img = img.flatten().reshape([-1,4096])\n",
    "    \n",
    "    labels.loc[labels['image'] == filenames[i], 'class'] = model.predict_classes(img, verbose=0)[0]\n",
    "\n",
    "labels.sort_values(by='class')\n",
    "labels['class'] = labels['class'].astype(int)\n",
    "labels.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:03:18.815434Z",
     "start_time": "2018-11-25T20:03:18.788995Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T20:03:31.999044Z",
     "start_time": "2018-11-25T20:03:31.934876Z"
    }
   },
   "outputs": [],
   "source": [
    "labels.to_csv(cfg.path+'output_guillaume/predictions/model_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:04:59.233721Z",
     "start_time": "2018-11-28T20:04:59.217946Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main_input = Input(shape=X_augm[0].shape, name='main_input')\n",
    "\n",
    "#cnn_model = load_model(cfg.path+'/output_guillaume/models/model_5.h5')\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:12:10.806519Z",
     "start_time": "2018-11-28T20:09:39.300671Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_layer_output = Model(inputs=model.input, outputs=model.get_layer('dropout_24').output)\n",
    "cnn_layer_output = cnn_layer_output.predict(X_augm)\n",
    "\n",
    "main_model = cnn_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FC for new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:12:11.025826Z",
     "start_time": "2018-11-28T20:12:10.814455Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "\n",
    "fc_model.add(Dense(512, activation='relu', input_shape=new_features[0].shape))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "fc_model.add(Dropout(0.5))\n",
    "fc_model.add(Dense(512, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "fc_model.add(Dropout(0.5))\n",
    "fc_model.add(Dense(512, activation='relu'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "fc_model.add(Dropout(0.5))\n",
    "\n",
    "fc_model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "\n",
    "fc_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:12:24.196825Z",
     "start_time": "2018-11-28T20:12:11.029826Z"
    }
   },
   "outputs": [],
   "source": [
    "history = fc_model.fit(\n",
    "    new_features, \n",
    "    Y_tmp,\n",
    "    epochs=4, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1,\n",
    "    class_weight=class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model.save(cfg.path+'/output_guillaume/models/model_fc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:12:24.214138Z",
     "start_time": "2018-11-28T20:12:24.200250Z"
    }
   },
   "outputs": [],
   "source": [
    "aux_input = Input(shape=new_features[0].shape, name='aux_input')\n",
    "\n",
    "#fc_model = load_model(cfg.path+'/output_guillaume/models/model_fc.h5')\n",
    "\n",
    "for layer in fc_model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:12:43.462109Z",
     "start_time": "2018-11-28T20:12:41.900106Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_layer_output = Model(inputs=fc_model.input, outputs=fc_model.get_layer('dropout_37').output)\n",
    "fc_layer_output = fc_layer_output.predict(new_features)\n",
    "\n",
    "aux_model = fc_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T20:13:13.964525Z",
     "start_time": "2018-11-28T20:13:13.950152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = concatenate([main_model, aux_model])\n",
    "\n",
    "output = Dense(512, activation='relu')(merged)\n",
    "output = Dense(cfg.n_classes, activation='softmax')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, aux_input], outputs=[output])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([X_augm, new_features], [Y_augm, Y_tmp], epochs=5, batch_size=cfg.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T16:32:20.680540Z",
     "start_time": "2018-11-28T16:32:18.435860Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model(cfg.path+'/output_guillaume/models/model_3_BEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T16:32:51.029616Z",
     "start_time": "2018-11-28T16:32:51.022339Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_layer(data):\n",
    "    \n",
    "    total_layers = len(model.layers)\n",
    "    \n",
    "    fl_index = total_layers-3\n",
    "    \n",
    "    feature_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer(index=fl_index).output)\n",
    "    \n",
    "    feature_layer_output = feature_layer_model.predict(data)\n",
    "    \n",
    "    return feature_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_cnn(x_train_cnn, y_train, cnn=None, num_round=100):\n",
    "    param = {'eta':0.1,\n",
    "             'max_depth':6,\n",
    "             'objective':'multi:softmax',\n",
    "             'n_estimators':175,\n",
    "             'silent':1,\n",
    "             'num_class':cfg.n_classes}\n",
    "    feat_out = get_feature_layer(cnn_model, x_train_cnn)\n",
    "    dtrain = xgboost.DMatrix(feat_out,\n",
    "                             label=y_train.idxmax(axis=1).values)\n",
    "    xgb_feature_layer = xgboost.train(param, dtrain, num_round)\n",
    "    return xgb_feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_layer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = load_model(cfg.path+'/output_guillaume/models/model_3.h5')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform and train on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(cfg.path+'/output_guillaume/models/model_4.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:10:46.892816Z",
     "start_time": "2018-11-26T16:10:45.940824Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=90,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 100\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(cfg.image_size, cfg.image_size),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(cfg.image_size, cfg.image_size),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:29:16.718313Z",
     "start_time": "2018-11-26T16:10:46.897891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['categorical_accuracy'])\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=cfg.n_epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(cfg.path+'/output_guillaume/models/model_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layers Output Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:21:22.638047Z",
     "start_time": "2018-11-27T10:21:21.496954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_3 = load_model(cfg.path+'/output_guillaume/models/model_3_BEST.h5')\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:20.007949Z",
     "start_time": "2018-11-27T10:28:20.002547Z"
    }
   },
   "outputs": [],
   "source": [
    "#model is the model you wanna extract the hidden layers output \n",
    "layer_names = ['conv2d_5', 'conv2d_6', 'conv2d_7']\n",
    "intermediate_layer_model = model_3.get_layer(layer_names[0]).output\n",
    "intermediate_output = intermediate_layer_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T10:28:13.254570Z",
     "start_time": "2018-11-27T10:28:12.772686Z"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_layer_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layer_names:\n",
    "    intermediate_layer_model = model_3.get_layer(layer).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=90,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 1000\n",
    "val_batchsize = 100\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(cfg.image_size, cfg.image_size),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(cfg.image_size, cfg.image_size),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['categorical_accuracy'])\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "697px",
    "left": "0px",
    "right": "1293px",
    "top": "110px",
    "width": "147px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
