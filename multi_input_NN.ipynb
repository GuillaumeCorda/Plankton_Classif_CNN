{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:54:49.108565Z",
     "start_time": "2018-12-12T13:54:41.148987Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from scipy.stats import moment \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import concatenate, merge\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D, LeakyReLU\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set global variables and model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:54:49.117467Z",
     "start_time": "2018-12-12T13:54:49.111656Z"
    }
   },
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    def __init__(self, path, data_location='data/', train_images_location='data/train_images/',\n",
    "                 test_images_location='/data/test_images/', image_size=224, n_classes=121, batch_size=64,\n",
    "                 n_epochs=10):\n",
    "        self.path = path\n",
    "        self.data_location = self.path + data_location\n",
    "        self.train_images_location = self.path + train_images_location\n",
    "        self.test_images_location = self.path + test_images_location \n",
    "        self.image_size = image_size\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:54:49.123606Z",
     "start_time": "2018-12-12T13:54:49.119820Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CONFIG(path='/Users/guillaumecorda/Desktop/UvA/Applied Machine Learning/Kaggle/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:54:49.386727Z",
     "start_time": "2018-12-12T13:54:49.127699Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(cfg.train_images_location) if i.endswith('.jpg')]\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    file_to_class = {el[0]:el[1] for el in reader}\n",
    "\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    class_counts = {}\n",
    "    for row in reader:\n",
    "        if(row[1] != 'class'):\n",
    "            class_counts[int(row[1])] = class_counts.get(int(row[1]), 0) + 1\n",
    "    max_nr = max(class_counts.values())\n",
    "    for key, value in class_counts.items():\n",
    "        class_counts[key] = int(class_counts[key] + (max_nr - class_counts[key])/6)\n",
    "\n",
    "X = np.empty([len(filenames), cfg.image_size, cfg.image_size,1])\n",
    "Y_ = np.empty([len(filenames)])\n",
    "Y = np.empty([sum(class_counts.values()),cfg.n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:56:43.189717Z",
     "start_time": "2018-12-19T19:56:43.183805Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_padding(i):\n",
    "    \n",
    "    if i%2 == 0: \n",
    "        return (int(i/2), int(i/2))\n",
    "    else:\n",
    "        return (int(i/2-.5), int(i/2+.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:56:50.781059Z",
     "start_time": "2018-12-19T19:56:50.772576Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_image(img):\n",
    "    \n",
    "    H, W = img.shape\n",
    "    if H == W:\n",
    "        return img\n",
    "    elif H > W:\n",
    "        return np.pad(img, ((0,0), get_padding(H-W)), 'constant')\n",
    "    \n",
    "    else:\n",
    "        return np.pad(img, (get_padding(W-H), (0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return resize(img, (cfg.image_size, cfg.image_size), mode='reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:56:28.508475Z",
     "start_time": "2018-12-12T13:54:49.400567Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(filenames)):\n",
    "    img = mpimg.imread(cfg.train_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    img = img.reshape(cfg.image_size, cfg.image_size,1)\n",
    "    X[i] = img\n",
    "    Y_[i] = int(file_to_class[filenames[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:57:57.389067Z",
     "start_time": "2018-12-12T13:56:28.730845Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.reshape(24204, cfg.image_size*cfg.image_size)\n",
    "\n",
    "sm = RandomOverSampler(ratio=class_counts)\n",
    "X, Y_ = sm.fit_sample(X, Y_)\n",
    "\n",
    "X = X.reshape(len(X), cfg.image_size, cfg.image_size, 1)\n",
    "for i in range(len(Y_)):\n",
    "    Y[i][int(Y_[i])] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:58:28.152391Z",
     "start_time": "2018-12-12T13:57:57.403956Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(total,X.shape[0]):\n",
    "    X[i] = np.rot90(X[i],(1+(i%4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T13:47:35.219Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:07:56.190257Z",
     "start_time": "2018-12-12T13:07:56.168861Z"
    }
   },
   "source": [
    "X = X.reshape((X.shape[0], cfg.image_size, cfg.image_size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:07:41.635806Z",
     "start_time": "2018-12-12T13:07:39.211351Z"
    }
   },
   "source": [
    "for i in range(X.shape[0]):    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:07:41.639354Z",
     "start_time": "2018-12-12T13:04:11.886Z"
    }
   },
   "outputs": [],
   "source": [
    "scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-11T14:03:48.499Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model(cfg.path+'output_guillaume/models/model__428.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-11T14:03:49.767Z"
    }
   },
   "outputs": [],
   "source": [
    "#select output\n",
    "intermediate_cnn_model = Model(inputs=cnn_model.input,\n",
    "                                 outputs=cnn_model.layers[-2].output)\n",
    "\n",
    "cnn_output = intermediate_cnn_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-11T14:04:02.204Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T13:58:29.268582Z",
     "start_time": "2018-12-12T13:58:28.168097Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=X[0].shape))\n",
    "cnn_model.add(LeakyReLU())\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "cnn_model.add(LeakyReLU())\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "cnn_model.add(LeakyReLU())\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(512))\n",
    "cnn_model.add(LeakyReLU())\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(512))\n",
    "cnn_model.add(LeakyReLU())\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:16:49.398659Z",
     "start_time": "2018-12-13T08:57:56.041130Z"
    }
   },
   "outputs": [],
   "source": [
    "history = cnn_model.fit(\n",
    "            X, \n",
    "            Y,\n",
    "            epochs=2, \n",
    "            batch_size=cfg.batch_size,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T17:22:05.928850Z",
     "start_time": "2018-12-11T17:11:27.640218Z"
    }
   },
   "outputs": [],
   "source": [
    "#select output\n",
    "intermediate_cnn_model = Model(inputs=cnn_model.input,\n",
    "                                 outputs=cnn_model.layers[-2].output)\n",
    "\n",
    "cnn_output = intermediate_cnn_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:16:50.920511Z",
     "start_time": "2018-12-13T13:16:49.468580Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.save(cfg.path+'/output_guillaume/models/model_new_cnn_224_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:51:14.581017Z",
     "start_time": "2018-12-11T18:51:12.651594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        featurewise_std_normalization=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                cfg.path+'data_formatted/train_images',  \n",
    "                target_size=(cfg.image_size, cfg.image_size),  \n",
    "                batch_size=cfg.batch_size,\n",
    "                class_mode='categorical',\n",
    "                color_mode='grayscale')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                cfg.path+'data_formatted/val_images',  \n",
    "                target_size=(cfg.image_size, cfg.image_size),  \n",
    "                batch_size=cfg.batch_size,\n",
    "                class_mode='categorical',\n",
    "                color_mode='grayscale')\n",
    "\n",
    "train_subm_generator = train_datagen.flow_from_directory(\n",
    "                cfg.path+'data_submission_train/',  \n",
    "                target_size=(cfg.image_size, cfg.image_size),  \n",
    "                batch_size=cfg.batch_size,\n",
    "                class_mode='categorical',\n",
    "                color_mode='grayscale')\n",
    "\n",
    "subm_generator = val_datagen.flow_from_directory(\n",
    "                cfg.path+'data_submission_test/',  \n",
    "                target_size=(cfg.image_size, cfg.image_size),  \n",
    "                batch_size=1,\n",
    "                class_mode='categorical',\n",
    "                color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:51:14.799502Z",
     "start_time": "2018-12-11T18:51:14.586929Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(cfg.image_size, cfg.image_size, 1)))\n",
    "cnn_model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "cnn_model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "cnn_model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(512, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(512, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:51:14.805094Z",
     "start_time": "2018-12-11T18:51:14.801579Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T18:59:55.296352Z",
     "start_time": "2018-12-11T18:51:14.808097Z"
    }
   },
   "outputs": [],
   "source": [
    "history = cnn_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:05:41.399647Z",
     "start_time": "2018-12-11T19:03:33.287538Z"
    }
   },
   "outputs": [],
   "source": [
    "#select output\n",
    "intermediate_cnn_model = Model(inputs=cnn_model.input,\n",
    "                                 outputs=cnn_model.layers[-2].output)\n",
    "\n",
    "cnn_output = intermediate_cnn_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute new features intrinsic to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:00:23.386406Z",
     "start_time": "2018-12-11T19:00:23.377689Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_new_features(filenames):\n",
    "    N = len(filenames)\n",
    "    output = np.zeros((N, 10))\n",
    "    classes = pd.read_csv(cfg.data_location + 'train_onelabel.csv')\n",
    "    for i, image in enumerate(filenames):\n",
    "        image = mpimg.imread(cfg.train_images_location + filenames[i])\n",
    "        h = image.shape[0]\n",
    "        w = image.shape[1]\n",
    "        h_ = h/w\n",
    "        w_ = w/h\n",
    "        h_2 = (h/w)**2\n",
    "        w_2 = (w/h)**2\n",
    "        m = np.mean(image)\n",
    "        moment_2 = moment(image.flatten(), moment=2)\n",
    "        moment_3 = moment(image.flatten(), moment=3)\n",
    "        label = classes['class'].loc[classes['image']==filenames[i]].values[0]\n",
    "        output[i] = np.array([h, w, h_, w_, h_2, w_2, m, moment_2, moment_3, label])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:01:41.470089Z",
     "start_time": "2018-12-11T19:00:23.625380Z"
    }
   },
   "outputs": [],
   "source": [
    "df = compute_new_features(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:01:41.480610Z",
     "start_time": "2018-12-11T19:01:41.472986Z"
    }
   },
   "outputs": [],
   "source": [
    "df[:,:9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:01:41.488719Z",
     "start_time": "2018-12-11T19:01:41.482807Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_targets(y_true):\n",
    "    N = len(y_true)\n",
    "    output = np.zeros(shape=(N, 121))\n",
    "    for i in range(N):\n",
    "        j=0\n",
    "        while j != y_true[i]:\n",
    "            j+=1\n",
    "        output[i][j]=1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:01:42.051671Z",
     "start_time": "2018-12-11T19:01:41.492526Z"
    }
   },
   "outputs": [],
   "source": [
    "target = format_targets(df[:,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:01:42.145463Z",
     "start_time": "2018-12-11T19:01:42.054357Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "\n",
    "fc_model.add(Dense(512, activation='relu',  input_shape=df[:,:9][0].shape))\n",
    "fc_model.add(Dropout(0.5))\n",
    "fc_model.add(Dense(512, activation='relu'))\n",
    "fc_model.add(Dropout(0.5))\n",
    "fc_model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "fc_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:02:09.989924Z",
     "start_time": "2018-12-11T19:01:42.147121Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = fc_model.fit(\n",
    "    df[:,:9], \n",
    "    target,\n",
    "    epochs=cfg.n_epochs, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:02:10.617957Z",
     "start_time": "2018-12-11T19:02:09.992534Z"
    }
   },
   "outputs": [],
   "source": [
    "#select output\n",
    "intermediate_layer_model = Model(inputs=fc_model.input,\n",
    "                                 outputs=fc_model.layers[-2].output)\n",
    "\n",
    "fc_output = intermediate_layer_model.predict(df[:,:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:02:10.625576Z",
     "start_time": "2018-12-11T19:02:10.619642Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:02:10.646301Z",
     "start_time": "2018-12-11T19:02:10.628208Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(cfg.path+'/output_guillaume/models/model_new_fc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:05:41.483681Z",
     "start_time": "2018-12-11T19:05:41.402341Z"
    }
   },
   "outputs": [],
   "source": [
    "new_input = np.concatenate([cnn_output, fc_output])\n",
    "print(new_input.shape)\n",
    "new_target = np.concatenate([Y, target])\n",
    "print(new_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:05:41.593879Z",
     "start_time": "2018-12-11T19:05:41.486264Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_model = Sequential()\n",
    "\n",
    "merge_model.add(Dense(512, activation='relu', input_shape=new_input[0].shape))\n",
    "merge_model.add(Dropout(0.5))\n",
    "merge_model.add(Dense(512, activation='relu'))\n",
    "merge_model.add(Dropout(0.5))\n",
    "merge_model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "merge_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "merge_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T19:05:41.629792Z",
     "start_time": "2018-12-11T19:05:41.597413Z"
    }
   },
   "outputs": [],
   "source": [
    "history = merge_model.fit(x = new_input,\n",
    "                        y = new_target,\n",
    "                        epochs=10, \n",
    "                        batch_size=cfg.batch_size,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:16:51.189829Z",
     "start_time": "2018-12-13T13:16:50.923329Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(cfg.path+'/data/test_images') if i.endswith('.jpg')]\n",
    "\n",
    "labels = pd.DataFrame(filenames, columns=['image'])\n",
    "labels['class'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T10:45:04.091216Z",
     "start_time": "2018-12-04T10:44:20.866Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(cfg.path+'/output_guillaume/models/model_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:22:10.701948Z",
     "start_time": "2018-12-13T13:16:51.193812Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(filenames)\n",
    "for i in range(total):\n",
    "    img = mpimg.imread(cfg.test_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    img = img.reshape(1,cfg.image_size, cfg.image_size,1)\n",
    "    labels.loc[labels['image'] == filenames[i], 'class'] = cnn_model.predict_classes(img, verbose=0)[0]\n",
    "\n",
    "labels.sort_values(by='class')\n",
    "labels['class'] = labels['class'].astype(int)\n",
    "labels.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:22:10.722942Z",
     "start_time": "2018-12-13T13:22:10.704432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:22:10.755955Z",
     "start_time": "2018-12-13T13:22:10.725020Z"
    }
   },
   "outputs": [],
   "source": [
    "labels.to_csv(cfg.path+'output_guillaume/predictions/model_new_cnn_224_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "* Try multi input with keras preproc\n",
    "* Try with different cnn\n",
    "* Try with different fcn\n",
    "* Try to change final architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "697px",
    "left": "0px",
    "right": "1308px",
    "top": "110px",
    "width": "132px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
