{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Load-and-train\" data-toc-modified-id=\"Load-and-train-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load and train</a></span></li><li><span><a href=\"#Set-global-variables-and-model-hyper-parameters\" data-toc-modified-id=\"Set-global-variables-and-model-hyper-parameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set global variables and model hyper-parameters</a></span></li><li><span><a href=\"#Load-data-and-labels\" data-toc-modified-id=\"Load-data-and-labels-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load data and labels</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Pre-processing\" data-toc-modified-id=\"Pre-processing-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Pre-processing</a></span></li><li><span><a href=\"#Class-imbalance\" data-toc-modified-id=\"Class-imbalance-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Class imbalance</a></span></li><li><span><a href=\"#CNN\" data-toc-modified-id=\"CNN-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>CNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-1---Best-so-far\" data-toc-modified-id=\"Model-1---Best-so-far-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Model 1 - Best so far</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Cross-Validation</a></span></li></ul></li><li><span><a href=\"#Model-2\" data-toc-modified-id=\"Model-2-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Model 2</a></span></li><li><span><a href=\"#Model-deep\" data-toc-modified-id=\"Model-deep-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Model deep</a></span></li></ul></li><li><span><a href=\"#Predictions\" data-toc-modified-id=\"Predictions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Predictions</a></span></li><li><span><a href=\"#Notes\" data-toc-modified-id=\"Notes-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Notes</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:21.680687Z",
     "start_time": "2018-12-19T19:59:18.619398Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.ndimage import shift\n",
    "import operator\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set global variables and model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:24.850558Z",
     "start_time": "2018-12-19T19:59:24.843774Z"
    }
   },
   "outputs": [],
   "source": [
    "class CONFIG():\n",
    "    def __init__(self, path, data_location='data/', train_images_location='data/train_images/',\n",
    "                 test_images_location='/data/test_images/', image_size=224, n_classes=121, batch_size=64,\n",
    "                 n_epochs=5):\n",
    "        self.path = path\n",
    "        self.data_location = self.path + data_location\n",
    "        self.train_images_location = self.path + train_images_location\n",
    "        self.test_images_location = self.path + test_images_location \n",
    "        self.image_size = image_size\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:25.349902Z",
     "start_time": "2018-12-19T19:59:25.343912Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = CONFIG(path='/Users/guillaumecorda/Desktop/UvA/Applied Machine Learning/Kaggle/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:28.160960Z",
     "start_time": "2018-12-19T19:59:27.922541Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(cfg.train_images_location) if i.endswith('.jpg')]\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    file_to_class = {el[0]:el[1] for el in reader}\n",
    "\n",
    "with open(cfg.data_location + 'train_onelabel.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    class_counts = {}\n",
    "    for row in reader:\n",
    "        if(row[1] != 'class'):\n",
    "            class_counts[int(row[1])] = class_counts.get(int(row[1]), 0) + 1\n",
    "    max_nr = max(class_counts.values())\n",
    "    for key, value in class_counts.items():\n",
    "        class_counts[key] = int(class_counts[key] + (max_nr - class_counts[key])/6)\n",
    "\n",
    "X = np.empty([len(filenames), cfg.image_size, cfg.image_size,1])\n",
    "Y_ = np.empty([len(filenames)])\n",
    "Y = np.empty([sum(class_counts.values()),cfg.n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:28.906307Z",
     "start_time": "2018-12-19T19:59:28.899787Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_padding(i):\n",
    "    \n",
    "    if i%2 == 0: \n",
    "        return (int(i/2), int(i/2))\n",
    "    else:\n",
    "        return (int(i/2-.5), int(i/2+.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:29.053464Z",
     "start_time": "2018-12-19T19:59:29.046369Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_image(img):\n",
    "    \n",
    "    H, W = img.shape\n",
    "    if H == W:\n",
    "        return img\n",
    "    elif H > W:\n",
    "        return np.pad(img, ((0,0), get_padding(H-W)), 'constant')\n",
    "    \n",
    "    else:\n",
    "        return np.pad(img, (get_padding(W-H), (0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:29.317926Z",
     "start_time": "2018-12-19T19:59:29.313520Z"
    }
   },
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return resize(img, (cfg.image_size, cfg.image_size), mode='reflect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T19:59:31.873289Z",
     "start_time": "2018-12-19T19:59:31.868915Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T20:00:43.157416Z",
     "start_time": "2018-12-19T20:00:15.942543Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(filenames)):\n",
    "    img = mpimg.imread(cfg.train_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    img = img.reshape(cfg.image_size, cfg.image_size,1)\n",
    "    X[i] = img\n",
    "    Y_[i] = int(file_to_class[filenames[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T20:00:43.484580Z",
     "start_time": "2018-12-19T20:00:43.159210Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.reshape(24204, cfg.image_size*cfg.image_size)\n",
    "\n",
    "sm = RandomOverSampler(ratio=class_counts)\n",
    "X, Y_ = sm.fit_sample(X, Y_)\n",
    "\n",
    "X = X.reshape(len(X), cfg.image_size, cfg.image_size, 1)\n",
    "for i in range(len(Y_)):\n",
    "    Y[i][int(Y_[i])] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T20:01:20.560335Z",
     "start_time": "2018-12-19T20:01:19.899052Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(24204, X.shape[0]):\n",
    "    X[i] = np.rot90(X[i],(1+(i%4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T20:01:21.543619Z",
     "start_time": "2018-12-19T20:01:21.090979Z"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "\n",
    "sub1 = plt.subplot(2,2,1)\n",
    "plt.imshow(X[446][:,:,0], cmap='binary')\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "sub1 = plt.subplot(2,2,2)\n",
    "rot = np.rot90(X[446],(1))\n",
    "plt.imshow(rot[:,:,0], cmap='binary')\n",
    "plt.title('Rotation')\n",
    "plt.axis('off')\n",
    "\n",
    "sub1 = plt.subplot(2,2,3)\n",
    "flip = np.fliplr(X[446])\n",
    "plt.imshow(flip[:,:,0], cmap='binary')\n",
    "plt.title('Flip Left-Right', loc=('left'))\n",
    "plt.axis('off')\n",
    "\n",
    "sub1 = plt.subplot(2,2,4)\n",
    "flip = np.flipud(X[446])\n",
    "plt.imshow(flip[:,:,0], cmap='binary')\n",
    "plt.title('Flip Up-Down')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-19T20:01:23.522090Z",
     "start_time": "2018-12-19T20:01:22.723304Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), padding='same', input_shape=(cfg.image_size, cfg.image_size, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-19T20:01:28.972Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    to_file='cnn.png',\n",
    "    show_shapes=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-19T20:01:23.779Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X, \n",
    "    Y,\n",
    "    epochs=5, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T13:10:04.919107Z",
     "start_time": "2018-12-14T13:10:04.913078Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T15:13:57.003146Z",
     "start_time": "2018-12-14T13:10:19.501542Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    history = model.fit(X_train, \n",
    "                        y_train,\n",
    "                        epochs=cfg.n_epochs,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=cfg.batch_size,\n",
    "                        verbose=1,\n",
    "                        callbacks=[EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:06:10.170013Z",
     "start_time": "2018-12-07T21:06:07.520619Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(cfg.path+'/output_guillaume/models/model_cross_val_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T14:32:16.046992Z",
     "start_time": "2018-12-15T14:32:15.839872Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(16, (3, 3), ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=.3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU(alpha=.3))\n",
    "\n",
    "model.add(Dense(cfg.n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T23:20:43.342813Z",
     "start_time": "2018-12-10T22:15:56.811508Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X, \n",
    "    Y,\n",
    "    epochs=10, \n",
    "    batch_size=cfg.batch_size,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T22:08:44.115586Z",
     "start_time": "2018-12-10T22:08:42.616642Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(cfg.path+'/output_guillaume/models/model__428.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', input_shape=X[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=X[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', input_shape=X[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(cfg.n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T22:08:47.765386Z",
     "start_time": "2018-12-10T22:08:47.478162Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [i for i in os.listdir(cfg.path+'/data/test_images') if i.endswith('.jpg')]\n",
    "\n",
    "labels = pd.DataFrame(filenames, columns=['image'])\n",
    "labels['class'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T21:06:15.613100Z",
     "start_time": "2018-12-07T21:06:10.435275Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(cfg.path+'/output_guillaume/models/model__428.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T22:13:16.807606Z",
     "start_time": "2018-12-10T22:08:59.881194Z"
    }
   },
   "outputs": [],
   "source": [
    "total = len(filenames)\n",
    "for i in range(total):\n",
    "    img = mpimg.imread(cfg.test_images_location + filenames[i])\n",
    "    img = np.absolute(np.divide(img.astype(float), 255) - 1.0)\n",
    "    img = resize_image(pad_image(img))\n",
    "    img = img.reshape(1, cfg.image_size, cfg.image_size,1)\n",
    "    labels.loc[labels['image'] == filenames[i], 'class'] = model.predict_classes(img, verbose=0)[0]\n",
    "\n",
    "labels.sort_values(by='class')\n",
    "labels['class'] = labels['class'].astype(int)\n",
    "labels.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T22:13:24.854945Z",
     "start_time": "2018-12-10T22:13:24.830229Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T22:13:34.956203Z",
     "start_time": "2018-12-10T22:13:34.875919Z"
    }
   },
   "outputs": [],
   "source": [
    "labels.to_csv(cfg.path+'output_guillaume/predictions/model__428.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Do**\n",
    "* Test sgd\n",
    "* Test with different im size\n",
    "* Test Leaky ReLu : https://keras.io/layers/advanced-activations/\n",
    "* Test Deeper cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "727px",
    "left": "0px",
    "right": "1308px",
    "top": "110px",
    "width": "132px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
